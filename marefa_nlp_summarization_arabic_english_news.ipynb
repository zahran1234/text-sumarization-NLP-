{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTw6B_rPJqRj",
        "outputId": "8d9e6a28-d902-432a-ddd9-4105393541c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.7.0\n",
            "  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf==3.15.3\n",
            "  Downloading protobuf-3.15.3-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (2.25.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (2022.6.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.7.0) (3.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.15.3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.7.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.7.0) (4.0.0)\n",
            "Building wheels for collected packages: nltk, sacremoses\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434694 sha256=a0e73e1b11b424dd9b3efbbae8d098a1be5a0f8a03eff07ea774bd0903d441e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6c9030e363e4505c2168dbd7ef6289fa177d5a148c6f312fc65ae5f663e3c518\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built nltk sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, protobuf, nltk, huggingface-hub, transformers\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "proto-plus 1.22.2 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.15.3 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.18.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.15.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.0.8 nltk-3.5 protobuf-3.15.3 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip3 install transformers==4.7.0 nltk==3.5 protobuf==3.15.3 sentencepiece==0.1.96\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz__vmkHiTY_",
        "outputId": "0c0b67cf-89ec-42aa-e26a-f0a17a92ada7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'rouge/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge-score) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (7.1.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=5f162f41e67d1cf9ba64cf3986b36bfacdec9b555a46daf11041616dc80d1a30\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r rouge/requirements.txt\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUdyo5uDnPw1",
        "outputId": "0b724856-6002-429a-f697-c49ac0afef16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J04rxgW4bOhk",
        "outputId": "4b36c738-5d84-4fec-dcbf-6c7d6b2eeadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'rouge/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge-score) (3.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.22.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r rouge/requirements.txt\n",
        "!pip install rouge-score\n",
        "import re \n",
        "from rouge_score import rouge_scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **rouge funcation to evaluate the model **"
      ],
      "metadata": {
        "id": "7w3vlv5D-0yj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kslmWbPa_e6"
      },
      "outputs": [],
      "source": [
        "def rouge(re,summary):\n",
        "  re=word_tokenize(re)\n",
        "  summary=word_tokenize(summary)\n",
        "  new_re=[]\n",
        "  new_summary=[]\n",
        "  x=1\n",
        "  for i in re:\n",
        "    if re.count(i)>1:\n",
        "      new_re.append(str(re.index(i)))\n",
        "    else:\n",
        "      new_re.append(str(x))\n",
        "      x=x+1\n",
        "  for i in summary :\n",
        "    if i in re:\n",
        "      new_summary.append(str(re.index(i))) \n",
        "    else :\n",
        "      new_summary.append('_') \n",
        "  x=\" \".join(new_summary)\n",
        "  y=\" \".join(new_re)\n",
        "  scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2','rougeL'])\n",
        "  scores = scorer.score(x,y)\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "m_name = \"marefa-nlp/summarization-arabic-english-news\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(m_name)\n",
        "model = AutoModelWithLMHead.from_pretrained(m_name).to(device)"
      ],
      "metadata": {
        "id": "i2EAmlZMeqgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXL_YPI6J92b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_summary(text, tokenizer, model, device=\"cpu\", num_beams=2):\n",
        "    if len(text.strip()) < 50:\n",
        "        return [\"Please provide more longer text\"]\n",
        "    \n",
        "    text = \"summarize: <paragraph> \" + \" <paragraph> \".join([ s.strip() for s in sent_tokenize(text) if s.strip() != \"\"]) + \" </s>\"\n",
        "    text = text.strip().replace(\"\\n\",\"\")\n",
        "    \n",
        "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "    \n",
        "    summary_ids = model.generate(\n",
        "            tokenized_text,\n",
        "            max_length=512,\n",
        "            num_beams=num_beams,\n",
        "            repetition_penalty=1.5, \n",
        "            length_penalty=1.0, \n",
        "            early_stopping=True\n",
        "\n",
        "    )\n",
        "    \n",
        "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return [ s.strip() for s in output.split(\"<hl>\") if s.strip() != \"\" ]\n",
        "    \n",
        "## Prepare Samples\n",
        "\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSZI92JjcGBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aim3ObkKCpdF",
        "outputId": "b73e17de-71dc-4f80-8fb6-422646164b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Article: \n",
            "  المكان جميل لاكن الاسعار عاليه جدا \n",
            "  الموظفين مش احسن حاجه \n",
            "  لا يوجد عماله مدربه\n",
            "  \n",
            "    \n",
            "\n",
            "===========\n",
            "Summary: \n",
            "\n",
            "\t- وقد اتصلت بـ (ماثيو) من قبل مدير شركة (إي بي سي)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "samples = [\n",
        "    \"\"\"\n",
        "  المكان جميل لاكن الاسعار عاليه جدا \n",
        "  الموظفين مش احسن حاجه \n",
        "  لا يوجد عماله مدربه\n",
        "  \n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "## Get summaries\n",
        "\n",
        "print(\"Original Article:\", samples[0])\n",
        "print(\"\\n===========\\nSummary: \\n\")\n",
        "hls = get_summary(samples[0], tokenizer, model, device)\n",
        "for hl in hls:\n",
        "    print(\"\\t-\", hl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0t7NXLqFQu8",
        "outputId": "a9db46d6-6e05-4a0d-b95b-a27179fe1ef4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "len(sent_tokenize(samples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr44EyjbFH63"
      },
      "outputs": [],
      "source": [
        "hls=\" \".join(hls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGw9QPkvXRVf",
        "outputId": "efaa9a85-c067-4eaa-f14b-9b99c9ee05b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "إريتريا هي دولة الحزب الواحد التي لم تجر فيها انتخابات تشريعية وطنية منذ الاستقلال. تملك أريتريا خط ساحل واسع على طول البحر الأحمر. وقد وضعت إريتريا في وضع فدرالي مع إثيوبيا لمدة 10 سنوات.\n"
          ]
        }
      ],
      "source": [
        "print(hls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a_cxcbtXVo7"
      },
      "outputs": [],
      "source": [
        "re=\"\"\"\n",
        "إريتريا هي دولة الحزب الواحد التي لم تجر فيها انتخابات تشريعية وطنية منذ الاستقلال. تأسست مملكة أكسوم ، التي تغطي الكثير من إريتريا الحديثة وشمال إثيوبيا خلال القرن الأول أو الثاني الميلادي. إن إنشاء إريتريا المعاصرة هو نتيجة لإدماج ممالك مستقلة وسلطنة مستقلة.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ILXKNXSYsj8",
        "outputId": "4d99f372-05de-4625-ca38-684ee7ad23a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Using default tokenizer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': Score(precision=0.41304347826086957, recall=1.0, fmeasure=0.5846153846153846),\n",
              " 'rouge2': Score(precision=0.28888888888888886, recall=0.7222222222222222, fmeasure=0.4126984126984127),\n",
              " 'rougeL': Score(precision=0.391304347826087, recall=0.9473684210526315, fmeasure=0.5538461538461538)}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "rouge(re,hls)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}